{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3163 entries, 0 to 3162\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Author       3163 non-null   object \n",
      " 1   Supervisor   3160 non-null   object \n",
      " 2   Departament  3163 non-null   object \n",
      " 3   Date         3163 non-null   object \n",
      " 4   Abstract     3157 non-null   object \n",
      " 5   Handle       3163 non-null   object \n",
      " 6   Language     3163 non-null   object \n",
      " 7   Keyword      3163 non-null   object \n",
      " 8   Title        3163 non-null   object \n",
      " 9   topic_label  3163 non-null   object \n",
      " 10  topic_score  3163 non-null   float64\n",
      " 11  topic_index  3163 non-null   int64  \n",
      " 12  subfield     3163 non-null   object \n",
      " 13  field        3163 non-null   object \n",
      " 14  domain       3163 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 370.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "phd_df = pd.read_csv(r'G:\\Unidades compartidas\\Planetary Wellbeing Mapping at UPF\\Dataset\\updated_datasets\\updated_phd_dataset.csv')\n",
    "phd_df['field'] = phd_df['field'].replace('Social Sciences', 'Social_Sciences')\n",
    "phd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21a5947b450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Create Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Load your DataFrame, assuming phd_df is your DataFrame\n",
    "\n",
    "# Define the departments available for selection\n",
    "departments = phd_df['Departament'].unique()\n",
    "\n",
    "# Create the layout of the app\n",
    "# Define the options for top N selection\n",
    "top_n_options = [5, 10, 15]  # You can adjust this list as needed\n",
    "\n",
    "# Create the layout of the app\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='department-dropdown',\n",
    "        options=[{'label': dept, 'value': dept} for dept in departments],\n",
    "        value=departments[0]  # Default value\n",
    "    ),\n",
    "    dcc.Slider(\n",
    "        id='top-n-slider',\n",
    "        min=5,\n",
    "        max=1000,\n",
    "        step=10,\n",
    "        value=10,  # Default value\n",
    "        #marks={i: str(i) for i in range(100, 1001)}  # Slider marks\n",
    "    ),\n",
    "    dcc.Graph(id='sankey-diagram')\n",
    "])\n",
    "\n",
    "# Callback to update the Sankey diagram based on the selected department and top N values\n",
    "@app.callback(\n",
    "    Output('sankey-diagram', 'figure'),\n",
    "    [Input('department-dropdown', 'value'),\n",
    "     Input('top-n-slider', 'value')]\n",
    ")\n",
    "def update_sankey(selected_department,top_n):\n",
    "    # Filter data based on selected department\n",
    "    filtered_df = phd_df[phd_df['Departament'] == selected_department]\n",
    "\n",
    "    # Aggregate data\n",
    "    agg_data = filtered_df.groupby(['domain', 'field', 'subfield', 'topic_label']).size().reset_index(name='counts')\n",
    "\n",
    "    # Limiting the number of nodes for simplicity (You can adjust this number)\n",
    "    \n",
    "    top_domains = agg_data.groupby('domain')['counts'].sum().nlargest(top_n).index\n",
    "    top_fields = agg_data.groupby('field')['counts'].sum().nlargest(top_n).index\n",
    "    top_subfields = agg_data.groupby('subfield')['counts'].sum().nlargest(top_n).index\n",
    "    top_topics = agg_data.groupby('topic_label')['counts'].sum().nlargest(top_n).index\n",
    "\n",
    "    # Filter aggregated data\n",
    "    agg_data = agg_data[agg_data['domain'].isin(top_domains) & agg_data['field'].isin(top_fields) & agg_data['subfield'].isin(top_subfields) & agg_data['topic_label'].isin(top_topics)]\n",
    "    # Assuming agg_data is your aggregated DataFrame\n",
    "\n",
    "    # Unique list of values while maintaining the order\n",
    "    unique_domains = agg_data['domain'].drop_duplicates().tolist()\n",
    "    unique_fields = agg_data['field'].drop_duplicates().tolist()\n",
    "    unique_subfields = agg_data['subfield'].drop_duplicates().tolist()\n",
    "\n",
    "    # Combine all unique values while maintaining order\n",
    "    all_nodes = unique_domains + unique_fields + unique_subfields\n",
    "\n",
    "    # Assuming agg_data is your aggregated DataFrame\n",
    "\n",
    "    # Get unique values for each category\n",
    "    domains = agg_data['domain'].drop_duplicates().tolist()\n",
    "    fields = agg_data['field'].drop_duplicates().tolist()\n",
    "    subfields = agg_data['subfield'].drop_duplicates().tolist()\n",
    "\n",
    "    # Function to determine the type of node for color mapping\n",
    "    def determine_node_type(node):\n",
    "        if node in domains:\n",
    "            return \"rgba(31, 119, 180, 0.4)\"\n",
    "        elif node in fields:\n",
    "            return \"rgba(128, 0, 128, 0.4)\"\n",
    "        elif node in subfields:\n",
    "            return \"rgba(255, 165, 0, 0.4)\"\n",
    "        else:\n",
    "            return \"grey\"  # Fallback color\n",
    "\n",
    "    # Map each node in all_nodes to its color based on the node type\n",
    "    node_colors = [determine_node_type(node) for node in all_nodes]\n",
    "\n",
    "    # Now, node_colors should correspond to the actual occurrences of nodes in the Sankey diagram\n",
    "\n",
    "    # Now continue with creating the links and the Sankey diagram as shown in previous examples\n",
    "    # Creating a mapping from node to its index\n",
    "    node_indices = {node: i for i, node in enumerate(all_nodes)}\n",
    "\n",
    "    # Group by 'domain', 'field', and 'subfield' and sum the 'counts'\n",
    "    grouped_links = agg_data.groupby(['domain', 'field', 'subfield'])['counts'].sum().reset_index()\n",
    "\n",
    "    # Create links with aggregated values\n",
    "    links = []\n",
    "    for _, row in grouped_links.iterrows():\n",
    "        # Domain to Field link\n",
    "        links.append({\n",
    "            'source': node_indices[row['domain']],\n",
    "            'target': node_indices[row['field']],\n",
    "            'value': row['counts']\n",
    "        })\n",
    "        # Field to Subfield link\n",
    "        # Ensure that the subfield is also in the node_indices mapping\n",
    "        if row['subfield'] in node_indices:\n",
    "            links.append({\n",
    "                'source': node_indices[row['field']],\n",
    "                'target': node_indices[row['subfield']],\n",
    "                'value': row['counts']\n",
    "            })\n",
    "\n",
    "    # Generate a unique color for each link if desired or use a default color\n",
    "    link_colors = [\"rgba(31, 119, 180, 0.4)\" for _ in links]\n",
    "\n",
    "    # Labels for each link (optional)\n",
    "    link_labels = [\"\"] * len(links)\n",
    "    # Assuming that agg_data is your DataFrame\n",
    "    node_colors_dict = {node: color for node, color in zip(all_nodes, node_colors)}\n",
    "    # First, create a sum of counts from domain to field regardless of subfield\n",
    "    domain_to_field_links = agg_data.groupby(['domain', 'field'])['counts'].sum().reset_index()\n",
    "\n",
    "    # Next, create links that are broken down from field to subfield\n",
    "    field_to_subfield_links = agg_data.groupby(['field', 'subfield'])['counts'].sum().reset_index()\n",
    "\n",
    "    # Now create your aggregated links\n",
    "    links = []\n",
    "    link_colors = []\n",
    "\n",
    "    # Create domain to field links\n",
    "    for _, row in domain_to_field_links.iterrows():\n",
    "        links.append({\n",
    "            'source': node_indices[row['domain']],\n",
    "            'target': node_indices[row['field']],\n",
    "            'value': row['counts']\n",
    "        })\n",
    "        # Set the link color to match the target (field) node's color\n",
    "        link_colors.append(node_colors_dict[all_nodes[node_indices[row['domain']]]])\n",
    "\n",
    "    # Create field to subfield links\n",
    "    for _, row in field_to_subfield_links.iterrows():\n",
    "        if row['subfield'] in node_indices:  # Check if the subfield is in the indices\n",
    "            links.append({\n",
    "                'source': node_indices[row['field']],\n",
    "                'target': node_indices[row['subfield']],\n",
    "                'value': row['counts']\n",
    "            })\n",
    "            # Set the link color to match the target (subfield) node's color\n",
    "            link_colors.append(node_colors_dict[all_nodes[node_indices[row['field']]]])\n",
    "\n",
    "    # Define link_labels\n",
    "    link_labels = [\"\"] * len(links)  # Empty labels for each link\n",
    "\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        orientation='h',\n",
    "        valueformat='.0f',\n",
    "        valuesuffix=' Thesis',\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=40,\n",
    "            line=dict(color='black', width = 0.2),\n",
    "            label=all_nodes,\n",
    "            color=node_colors\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=[link['source'] for link in links],\n",
    "            target=[link['target'] for link in links],\n",
    "            value=[link['value'] for link in links],\n",
    "            color=link_colors,\n",
    "            label=link_labels\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # Update layout to adjust figure size\n",
    "    fig.update_layout(\n",
    "        title_text=\"Sankey Diagram\",\n",
    "        font_size=10,\n",
    "        width=1200,  # Width of the figure in pixels\n",
    "        height=600   # Height of the figure in pixels\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    return fig  # Return the updated figure\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
